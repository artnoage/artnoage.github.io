  <section id="Master Thesis Topics">
<div class="container">
  <h3>Available topics</h3>
  <div class="panel panel-default">
    <div class="panel-body">
		<h5>
			&nbsp;&nbsp;<strong>  Meta-learning techniques in Reinforcement Learning, with applications
on multi-agent cooperative tasks. The game of Hanabi</strong>
		</h5>
      <article>
        <p>
           <span class="math inline"> Recently Google released a new testbed for RL. The game of Hanabi has many new complexities that older testbed games like Chess and Go
             do not exhibit. Apart from a quite big state space, the game involves partial information and cooperation between agents. This cooperation is extremely difficult
          to model because communication between agent can contain meta-information. Although agents that are trained together can achieve high scores, when aggents with different
          learning experience meet, they exhibit poor performance. The goal is to apply meta-learning ideas to train the agents, so they will be able to adapt to new enviroments (different set of cooperative agents).
          </span>
        </p>
        <p>
            <em>Difficulty &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          </em> <i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i>
            &nbsp;&nbsp;
        </p>
        <p>
            <em>Independence&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          </em>  <i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star-o"></i><i class="fa fa-star-o"></i>
            &nbsp;&nbsp;
        </p>
         <p>
            <em>Likelihood of novel results&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
           </em>  <i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star-o"></i>
            &nbsp;&nbsp;
        </p>
    </article>
    <article>
      Prequisites: Know how to build and train Neural Networks in tensorflow or Keras, Basic knowledge of probability theory and Markov decision processes.
      </article>
      <article>
        Bonus for having knowledge in: Mainstream RL algorithms. Mathematical Logic.
      </article>
    </div>
	      <div class="panel-body">
		<h5>
			&nbsp;&nbsp;<strong> Risk-sensitive, partially-observable markov decision processes. A theoretical project</strong>
		</h5>
      <article>
        <p>
           <span class="math inline"> We have a new model for solving a group of Risk-Sensitive Pratially observable Markov decision processes problems 
and there is need for testing this model with some numerical experiments. The project needs strong background in mathematics and especially probability 
		   theory and it has a big likelihood for a publication.
          </span>
        </p>
        <p>
            <em>Difficulty &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          </em>  <i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star-o"></i>
            &nbsp;&nbsp;
        </p>
        <p>
            <em>Independence&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          </em>  <i class="fa fa-star"></i><i class="fa fa-star-o"></i><i class="fa fa-star-o"></i><i class="fa fa-star-o"></i><i class="fa fa-star-o"></i>
            &nbsp;&nbsp;
        </p>
         <p>
            <em>Likelihood of novel results&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
           </em>  <i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i>
            &nbsp;&nbsp;
        </p>
    </article>
    <article>
      Prequisites: Basic knowledge of probability theory and Markov decision processes. Programming experience (most likely matlab).
      </article>
      <article>
        Bonus for having knowledge in/experience with: Risk-sensitivity, Change of measures (probability).
      </article>
    </div>
	  	      <div class="panel-body">
		<h5>
			&nbsp;&nbsp;<strong> Risk-sensitive, partially-observable markov decision processes with application on Texas Hold'em</strong>
		</h5>
      <article>
        <p>
           <span class="math inline"> The aim is to create and test a model of Risk-sensitive, partially-observable markov decision processes, that can be
		   tested on a game (like texas holdem). The thesis does not have to be theoretical in natur. Creating an algorith and comparing it
		   with the state of the art algorithms would be sufficient. 
          </span>
        </p>
        <p>
            <em>Difficulty &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          </em>  <i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star-o"></i>
            &nbsp;&nbsp;
        </p>
        <p>
            <em>Independence&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          </em>  <i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star-o"></i><i class="fa fa-star-o"></i>
            &nbsp;&nbsp;
        </p>
         <p>
            <em>Likelihood of novel results&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
           </em>  <i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star-o"></i><i class="fa fa-star-o"></i>
            &nbsp;&nbsp;
        </p>
    </article>
    <article>
      Prequisites: Know how to build and train Neural Networks in tensorflow or Keras, Basic knowledge of probability theory and Markov decision processes.
      </article>
      <article>
        Bonus for having knowledge in: Mainstream RL algorithms. Mathematical Logic.
      </article>
    </div>
	      <div class="panel-body">
		<h5>
			&nbsp;&nbsp;<strong> Training generative networks with optimal transport methods</strong>
		</h5>
      <article>
        <p>
          Since the introduction of GANs by Goodfellow et al., there were many attemtpts to train generative networks using a
		two network system, where the first acts as a guide/trainer/supervisor to the second. Among them, WGANs became very popular
		due to the simplicity of the mathematical formula/background. With my student Jan Tinapp, we introduced a new algorithm that is
		based on Optimal Transport but does not train like WGANs. I need a student to continue this work and find ways to treat the drowbacks
		of this approach.
	      </p>
        <p>
            <em>Difficulty &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          </em> <i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star-o"></i><i class="fa fa-star-o"></i>
            &nbsp;&nbsp;
        </p>
        <p>
            <em>Independence&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          </em>  <i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star-o"></i><i class="fa fa-star-o"></i>
            &nbsp;&nbsp;
        </p>
         <p>
            <em>Likelihood of novel results&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
           </em>  <i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star-o"></i><i class="fa fa-star-o"></i>
            &nbsp;&nbsp;
        </p>
    </article>
    <article>
      Prequisites: Know how to build and train Neural Networks in tensorflow or Keras, Basic knowledge of probability theory and Markov decision processes.
      </article>
      <article>
         Bonus for having knowledge in/experience with: GANS.
      </article>
    </div>
    </div>
  </div>
   </section>



 
